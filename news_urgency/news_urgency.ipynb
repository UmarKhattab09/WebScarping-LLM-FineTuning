{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4903db4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khatt\\Documents\\WebScarping-LLM-FineTuning\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from transformers import pipeline\n",
    "env_path = os.path.abspath(\"../trainingllm/.env\") \n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "hf_token=os.getenv(\"huggingfacetoken\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf7176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khatt\\Documents\\WebScarping-LLM-FineTuning\\venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\khatt\\Documents\\WebScarping-LLM-FineTuning\\venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:935: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "token = hf_token\n",
    "model_id = \"KS-Vijay/urgency-model-aura\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, use_auth_token=token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=token)\n",
    "model_name = \"KS-Vijay/urgency-model-aura\"\n",
    "res = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    )   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530f3fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d54528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9999678134918213}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I am fine\"\n",
    "result= res(text)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01cbe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khatt\\Documents\\WebScarping-LLM-FineTuning\\venv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1182: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: My internet is slow, please fix it.\n",
      "Prediction: [{'label': 'LABEL_1', 'score': 0.999969482421875}]\n",
      "\n",
      "Text: There is a fire in my building!\n",
      "Prediction: [{'label': 'LABEL_1', 'score': 0.9999721050262451}]\n",
      "\n",
      "Text: I'd like to schedule a meeting next week.\n",
      "Prediction: [{'label': 'LABEL_1', 'score': 0.9999653100967407}]\n",
      "\n",
      "Text: Help! Someone collapsed at the station.\n",
      "Prediction: [{'label': 'LABEL_1', 'score': 0.9999712705612183}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_id, use_auth_token=token)\n",
    "\n",
    "id2label = config.id2label\n",
    "\n",
    "texts = [\n",
    "    \"My internet is slow, please fix it.\",\n",
    "    \"There is a fire in my building!\",\n",
    "    \"I'd like to schedule a meeting next week.\",\n",
    "    \"Help! Someone collapsed at the station.\",\n",
    "]\n",
    "\n",
    "for t in texts:\n",
    "    result = res(t)\n",
    "    readable = [{\"label\": id2label[int(item['label'].split('_')[-1])], \"score\": item[\"score\"]} for item in result]\n",
    "    print(f\"Text: {t}\\nPrediction: {readable}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07ba3899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'There is a fire in the building and people are trapped.', 'labels': ['Critical', 'High', 'Medium', 'Low'], 'scores': [0.49490106105804443, 0.2296009510755539, 0.14468853175640106, 0.13080942630767822]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "zero_shot = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "labels = [\"Critical\", \"High\", \"Medium\", \"Low\"]\n",
    "text = \"There is a fire in the building and people are trapped.\"\n",
    "\n",
    "result = zero_shot(text, candidate_labels=labels)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
